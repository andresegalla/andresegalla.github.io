{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fddcf2e0",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Machine Learning problems are generally framed into problems of minimizing some kind of **Loss Function**.\n",
    "Intuitively, Loss Functions are functions that measure how well some model is performing in the available data of the problem at hand, and models with lower Losses are preferred. \n",
    "\n",
    "A natural and important question that arises is precisely which Loss Function to choose for some given problem. There is a extensive list of available Loss Functions to choose from (and you can always invent new ones) and although some choices might be obvious or straightforward for some problems (you might usufally not even think about it and just choose the default ones from your library at hand), it might not always be the case. If you find yourself in the latter case, it might be useful to think about the problem from some a \"first principles\" angle to help understand how to choose it more wisely.\n",
    "\n",
    "The goal here is to briefly discuss how Loss Functions in ML problems arise naturally from a Bayesian perspective. \n",
    "We'll focus on **supervised learning** problems.\n",
    "\n",
    "\n",
    "\n",
    "# Loss Functions from a Bayesian perspective\n",
    "\n",
    "\n",
    "Let's supposed we have $N$ data points available $D=\\{(x_i, y_i)\\}_{i=1} ^ N$, where $x_i \\in \\mathcal{X}$ are the *inputs* and $y_i \\in \\mathcal{Y}$ the respetive *outputs*, or *targets*, and we want to learn some relationship, denoted by $f$, between inputs and targets:\n",
    "\n",
    "$$f : \\mathcal{X} \\to \\mathcal{Y}$$\n",
    "\n",
    "This is a general **supervised learning setting**. Since we almost never have *complete information* and our data is corrupted by *noises* of several natures, it is natural to include uncertainty into the problem using probabilities. *Estimates without any uncertainty statement are meaningless*.\n",
    "\n",
    "With that let's just define some notation:\n",
    "\n",
    "- Capital letters $X$ and $Y$ are **[random variables](https://en.wikipedia.org/wiki/Random_variable)**, while small letters $x$, $y$ are *realizations* of the random variables $X$ and $Y$, respectively.\n",
    "\n",
    "Finally, we define:\n",
    "\n",
    "$$p(y|x) := Prob(Y=y | X=x),$$\n",
    "\n",
    "as the *conditional probability* of observing a $Y=y$ *given* that $X=x$ is observed. **So, our supervised learning problem is precisely to estimate $p(y|x)$, given all available information at hand**, $I$, which we can write as $p(y|x, I)$. In case of continuous $y$, $p(y|x)$ is usually called *probability densisity function* (pdf), while for the case of discrete $y$, $p(y|x)$ is a *probability mass funcion* (pmf).\n",
    "\n",
    "Now, what is $I$ and how do we leverage it? As said above, $I$ is whatever information about the problem we have at hand and can use to constrain our problem. The most obvious piece of relevant information is of course the available data $D$. Also, in order to be able to proceed, we assume some kind of **parametrization** of $p(y|x)$ to constrain the solution space and to allow us using efficient optimization algorithms to find good solutions. The choice of the parametrization is crucial and is what leads to the form of the main term of the Loss function. Let's write this as follows:\n",
    "\n",
    "$$p(y|x) = p(y | \\lambda (x)),$$ (parametrization)\n",
    "\n",
    "where $p$ is now parametrized by $\\lambda$, which can depend on $x$. \n",
    "\n",
    "As example, supposing both $x$ and $y$ are real numbers, one could use the *gaussian distribution*, where $\\lambda (x) = (\\mu (x), \\sigma (x))$ are the expectation and standard deviation, respectively :\n",
    "\n",
    "$$p(y|x) = \\mathcal{N}(y | \\mu(x), \\sigma(x)),$$ \n",
    "\n",
    "\n",
    "Our goal in this case would be to estimate $\\mu(x)$ and  $\\sigma(x)$. \n",
    "\n",
    "Now, in ML what we do is to build some **model** to predict the parameters $\\lambda (x)$. The model is in turn a function, $m$, that is parametrized by its own parameters $\\theta$:\n",
    "\n",
    "$$\\lambda (x) = m(x | \\theta).$$\n",
    "\n",
    "Fitting or training a model means finding a suitable set of parameters $\\theta$. With that we have in principle solved our problem, because from $\\theta$ we get to what we initially wanted to estimate, which is the conditional distribution $p(y|x)$:\n",
    "\n",
    "$$\\theta \\to \\lambda \\to p(y|x).$$\n",
    "\n",
    "With that, we can finally re-write the conditional distribution as:\n",
    "\n",
    "\n",
    "$$p(y|x) = p(y | \\lambda (x)) = p(y | x, \\theta),$$ \n",
    "\n",
    "where we replaced the $\\lambda (x)$ in the conditioning by $x, \\theta$ and omitted the dependence on the model function $m$ to simplify notation. \n",
    "\n",
    "## Posterior\n",
    "\n",
    "Our goal is to find $\\theta$, but according to which criterium? Well, maybe the simplest one would be: *the most likely, given our data*. We can write precisely that as $p(\\theta | D)$ and the solution would be:\n",
    "\n",
    "$$\\theta^* =  \\underset{\\theta}{\\text{argmax }}  p(\\theta | D).$$\n",
    "\n",
    "$p(\\theta | D)$ is called the **posterior** distribution of $\\theta$ given $D$ and $\\theta^*$ is called the **Maximum a Posteriori (MAP)** estimate. We can rewrite $p(\\theta | D)$ using [Bayes' theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem):\n",
    "\n",
    "$$p(\\theta | D) = \\frac{p(D|\\theta)p(\\theta)}{p(D)},$$\n",
    "\n",
    "where: \n",
    "\n",
    "- $p(D|\\theta)$ is the **likelihood function**,\n",
    "- $p(\\theta)$ is the **prior**,\n",
    "- $p(D) = \\int  p(D|\\theta)p(\\theta) d\\theta$ is the **evidence**.\n",
    "\n",
    "To increase numerical stability, it is convenient to maximize the **log** of the posterior (which does not change the maximum):\n",
    "\n",
    "$$\\log p(\\theta | D) = \\log p(D|\\theta) + \\log p(\\theta) - \\log p(D).$$\n",
    "\n",
    "Since maximizing a function is equivalent to minimizing its opposite, we can identify the negative log posterior as the Loss Function $\\mathcal{L}$ of our problem:\n",
    "\n",
    "$$Loss = \\mathcal{L}(\\theta, D) := - \\log  p(\\theta | D).$$\n",
    "\n",
    "Further, if we can assume that all $\\{(x_i, y_i$)\\} are (i.i.d), we have:\n",
    "\n",
    "$$\\log p(D|\\theta) = \\log \\prod\\limits_{i} p(y_i, x_i|\\theta) = \\log \\prod\\limits_{i} p(y_i|x_i,\\theta)p(x_i) = \\sum\\limits_{i} \\log p(y_i|x_i,\\theta) + \\sum\\limits_{i} p(x_i),$$ \n",
    "\n",
    "which leads us to:\n",
    "\n",
    "$$ \\mathcal{L}(\\theta, D) = - \\sum\\limits_{i} \\log p(y_i|x_i,\\theta) - \\log p(\\theta) + K,$$\n",
    "\n",
    "where $K$ is a constant that does not depend on $\\theta$ and is therefore irrelevant for our optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c550f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
